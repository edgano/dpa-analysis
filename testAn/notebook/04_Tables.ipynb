{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tables\n",
    "\n",
    "The tables generated below are used both as guide trees in the progressive\n",
    "alignment proceedure as well as trees used in the clustering step \n",
    "of the regressive alignment proceedure.\n",
    "\n",
    "\n",
    "The generated tables can be found in the `results/tables/` directory of this repository.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "# Import python packages #\n",
    "##########################\n",
    "\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "# Change directory relative to repository home #\n",
    "################################################\n",
    "\n",
    "pwd = os.getcwd()\n",
    "work_dir=pwd+\"/..\"\n",
    "os.chdir(work_dir)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "# Read in the number of sequences for each dataset #\n",
    "####################################################\n",
    "\n",
    "with open(\"data/num_seqs.csv\", mode='r') as infile:\n",
    "    reader = csv.reader(infile, delimiter='\\t')\n",
    "    sizes_dict = {rows[0]:rows[1] for rows in reader}\n",
    "    \n",
    "print(sizes_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "# Function to read in accuracy and scores files #\n",
    "#################################################\n",
    "\n",
    "def scores_to_dict(scores_dir, scores_dict, tag):\n",
    "    scores_list=[]\n",
    "    for score_file in os.listdir(scores_dir):\n",
    "        family, align_type, bucket, aligner, tree, score_type = score_file.split('.')\n",
    "        y = tuple([tag, align_type, aligner, tree, family, score_type])\n",
    "        with open(scores_dir + score_file, 'r') as infile:\n",
    "            data = infile.read()\n",
    "        scores_dict[y]=data.rstrip()\n",
    "    return scores_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Read in the full and reference datasets scores #\n",
    "##################################################\n",
    "\n",
    "scores_dict = {}\n",
    "full_scores_dir=\"results/individual_scores/\"\n",
    "scores_dict = scores_to_dict(full_scores_dir, scores_dict, \"full\")\n",
    "\n",
    "ref_scores_dir=\"results_reference/individual_scores/\"\n",
    "scores_dict = scores_to_dict(ref_scores_dir, scores_dict, \"ref\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################\n",
    "# Create a dictionary for average TC scores and CPU time when above 10,000 seqs #\n",
    "#################################################################################\n",
    "\n",
    "# Dictionary of the average TC scores and CPU time\n",
    "full_top20_tc_avg_dict={}\n",
    "ref_top20_tc_avg_dict={}\n",
    "cpu_top20_dict={}\n",
    "\n",
    "# Take all datasets and create a dictionary of average scores\n",
    "datasets=set([k[1]+'/'+k[2]+'/'+k[3] for k,v in scores_dict.items() ])\n",
    "\n",
    "# Calculate average TC score for each of the full datasets with over 10,000 sequences\n",
    "for dataset in datasets:\n",
    "    key = dataset.split(\"/\")\n",
    "    i = [v for k,v in scores_dict.items() if k[0]=='full' and k[1]==key[0] and k[2]==key[1] and k[3]==key[2] and int(sizes_dict[k[4]]) > 10000 and k[5]=='tc']\n",
    "    l = [float(j) for j in i]\n",
    "    if (len(l)==20):\n",
    "        avg = sum(l)/float(len(l))\n",
    "        full_top20_tc_avg_dict[tuple(key)]=avg\n",
    "\n",
    "# Calculate average TC for each of the reference datasets\n",
    "for dataset in datasets:\n",
    "    key = dataset.split(\"/\")\n",
    "    i = [v for k,v in scores_dict.items() if k[0]=='ref' and k[1]==key[0] and k[2]==key[1] and k[3]==key[2] and int(sizes_dict[k[4]]) > 10000 and k[5]=='tc']\n",
    "    l = [float(j) for j in i]\n",
    "    if (len(l)==20):\n",
    "        avg = sum(l)/float(len(l))\n",
    "        ref_top20_tc_avg_dict[tuple(key)]=avg\n",
    "\n",
    "# Calculate average CPU time required for each the datasets with over 10,000 sequences\n",
    "for dataset in datasets:\n",
    "    key = dataset.split(\"/\")\n",
    "    i = [v for k,v in scores_dict.items() if k[0]=='full' and k[1]==key[0] and k[2]==key[1] and k[3]==key[2] and int(sizes_dict[k[4]]) > 10000 and k[5]=='cpu']\n",
    "    l = [float(j) for j in i]\n",
    "    if (len(l)==20):\n",
    "        avg = sum(l)/float(len(l))\n",
    "        cpu_top20_dict[tuple(key)]=avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "# Export Table 1 as CSV #\n",
    "#########################\n",
    "\n",
    "with open('results/tables/table1.csv', 'w') as csvfile:\n",
    "    filewriter = csv.writer(csvfile, delimiter=',')\n",
    "\n",
    "    filewriter.writerow(['','','non-regressive','regressive','reference','non-regressive','regressive'])\n",
    "    filewriter.writerow(['tree method','MSA algorithm','score %','score %','score %','cpu time (ms)','cpu time (ms)'])\n",
    "\n",
    "    f_dic, r_dic, cpu_dic, aligner, tree = full_top20_tc_avg_dict, ref_top20_tc_avg_dict, cpu_top20_dict, 'MAFFT-FFTNS1', 'MAFFT_PARTTREE'\n",
    "    filewriter.writerow(['PartTree','Fftns1',round(f_dic['std_align',aligner,tree],2),round(f_dic['dpa_align',aligner,tree],2),round(r_dic['std_align',aligner,tree],2),cpu_dic['std_align',aligner,tree],cpu_dic['dpa_align',aligner,tree]])\n",
    " \n",
    "    f_dic, r_dic, cpu_dic, aligner, tree = full_top20_tc_avg_dict, ref_top20_tc_avg_dict, cpu_top20_dict, 'MAFFT-FFTNS1', 'CLUSTALO'\n",
    "    filewriter.writerow(['mBed','Fftns1',round(f_dic['std_align',aligner,tree],2),round(f_dic['dpa_align',aligner,tree],2),round(r_dic['std_align',aligner,tree],2),cpu_dic['std_align',aligner,tree],cpu_dic['dpa_align',aligner,tree]])\n",
    " \n",
    "    f_dic, r_dic, cpu_dic, aligner, tree = full_top20_tc_avg_dict, ref_top20_tc_avg_dict, cpu_top20_dict, 'CLUSTALO', 'MAFFT_PARTTREE'\n",
    "    filewriter.writerow(['PartTree','ClustalO',round(f_dic['std_align',aligner,tree],2),round(f_dic['dpa_align',aligner,tree],2),round(r_dic['std_align',aligner,tree],2),cpu_dic['std_align',aligner,tree],cpu_dic['dpa_align',aligner,tree]])\n",
    "\n",
    "    f_dic, r_dic, cpu_dic, aligner, tree = full_top20_tc_avg_dict, ref_top20_tc_avg_dict, cpu_top20_dict, 'CLUSTALO', 'CLUSTALO'\n",
    "    filewriter.writerow(['mBed','ClustalO',round(f_dic['std_align',aligner,tree],2),round(f_dic['dpa_align',aligner,tree],2),round(r_dic['std_align',aligner,tree],2),cpu_dic['std_align',aligner,tree],cpu_dic['dpa_align',aligner,tree]])\n",
    "    \n",
    "    filewriter.writerow(['Average','','','','','',''])\n",
    "    filewriter.writerow(['','','','','','',''])\n",
    "    \n",
    "    f_dic, r_dic, cpu_dic, aligner, tree = full_top20_tc_avg_dict, ref_top20_tc_avg_dict, cpu_top20_dict, 'UPP', 'DEFAULT'\n",
    "    filewriter.writerow(['default/mBed','UPP',round(f_dic['default_align',aligner,tree],2),round(f_dic['dpa_align',aligner,'CLUSTALO'],2),round(r_dic['default_align',aligner,tree],2),cpu_dic['default_align',aligner,'DEFAULT'],cpu_dic['dpa_align',aligner,'CLUSTALO']])\n",
    " \n",
    "    f_dic, r_dic, cpu_dic, aligner, tree = full_top20_tc_avg_dict, ref_top20_tc_avg_dict, cpu_top20_dict, 'MAFFT-SPARSECORE', 'DEFAULT'\n",
    "    filewriter.writerow(['default/mBed','Sparsecore',round(f_dic['default_align',aligner,tree],2),round(f_dic['dpa_align',aligner,'CLUSTALO'],2),round(r_dic['default_align',aligner,tree],2),cpu_dic['default_align',aligner,'DEFAULT'],cpu_dic['dpa_align',aligner,'CLUSTALO']])\n",
    " \n",
    "    f_dic, r_dic, cpu_dic, aligner, tree = full_top20_tc_avg_dict, ref_top20_tc_avg_dict, cpu_top20_dict, 'MAFFT-GINSI', 'MAFFT_PARTTREE'\n",
    "    filewriter.writerow(['PartTree','Gins1','-',round(f_dic['dpa_align',aligner,tree],2),round(r_dic['std_align',aligner,tree],2),'-',cpu_dic['dpa_align',aligner,tree]])\n",
    "\n",
    "    f_dic, r_dic, cpu_dic, aligner, tree = full_top20_tc_avg_dict, ref_top20_tc_avg_dict, cpu_top20_dict, 'MAFFT-GINSI', 'CLUSTALO'\n",
    "    filewriter.writerow(['mBed','Gins1','-',round(f_dic['dpa_align',aligner,tree],2),round(r_dic['std_align',aligner,tree],2),'-',cpu_dic['dpa_align',aligner,tree]]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################\n",
    "# Export all raw results as CSV table #\n",
    "#######################################\n",
    "\n",
    "with open('results/tables/full_table_sp.csv', 'w') as csvfile:\n",
    "    filewriter = csv.writer(csvfile, delimiter=',')\n",
    "    for e in scores_dict:\n",
    "        if e[5] == 'sp':\n",
    "            filewriter.writerow([e[0], e[1], e[2], e[3], e[4], sizes_dict[e[4]], scores_dict[e]])\n",
    "            \n",
    "with open('results/tables/full_table_tc.csv', 'w') as csvfile:\n",
    "    filewriter = csv.writer(csvfile, delimiter=',')\n",
    "    for e in scores_dict:\n",
    "        if e[5] == 'tc':\n",
    "            filewriter.writerow([e[0], e[1], e[2], e[3], e[4], sizes_dict[e[4]], scores_dict[e]])\n",
    "\n",
    "with open('results/tables/full_table_cpu.csv', 'w') as csvfile:\n",
    "    filewriter = csv.writer(csvfile, delimiter=',')\n",
    "    for e in scores_dict:\n",
    "        if e[5] == 'cpu':\n",
    "            filewriter.writerow([e[0], e[1], e[2], e[3], e[4], sizes_dict[e[4]], scores_dict[e]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "# Export table for CCA Figure 2B #\n",
    "##################################\n",
    "\n",
    "with open('results/tables/figure2b.csv', 'w') as csvfile:\n",
    "    filewriter = csv.writer(csvfile, delimiter=',')\n",
    "    \n",
    "    f_dic = full_top20_tc_avg_dict\n",
    "    \n",
    "    filewriter.writerow(['reg_method','tree_method','align_method','accuracy'])\n",
    "    \n",
    "    filewriter.writerow(['Non-Regressive','PartTree','Fftns1',f_dic['std_align','MAFFT-FFTNS1','MAFFT_PARTTREE']])\n",
    "    filewriter.writerow(['Non-Regressive','mBed','Fftns1',f_dic['std_align','MAFFT-FFTNS1','CLUSTALO']])\n",
    "    filewriter.writerow(['Non-Regressive','PartTree','ClustalO',f_dic['std_align','CLUSTALO','MAFFT_PARTTREE']])\n",
    "    filewriter.writerow(['Non-Regressive','mBed','ClustalO',f_dic['std_align','CLUSTALO','CLUSTALO']])\n",
    "    \n",
    "    filewriter.writerow(['Non-Regressive','UPP Tree','UPP',f_dic['default_align','UPP','DEFAULT']])\n",
    "    filewriter.writerow(['Non-Regressive','Sparsecore Tree','Sparsecore',f_dic['default_align','MAFFT-SPARSECORE','DEFAULT']])\n",
    "    \n",
    "    filewriter.writerow(['Regressive','PartTree','Fftns1',f_dic['dpa_align','MAFFT-FFTNS1','MAFFT_PARTTREE']])\n",
    "    filewriter.writerow(['Regressive','mBed','Fftns1',f_dic['dpa_align','MAFFT-FFTNS1','CLUSTALO']])\n",
    "    filewriter.writerow(['Regressive','PartTree','ClustalO',f_dic['dpa_align','CLUSTALO','MAFFT_PARTTREE']])\n",
    "    filewriter.writerow(['Regressive','mBed','ClustalO',f_dic['dpa_align','CLUSTALO','CLUSTALO']])\n",
    "    \n",
    "    filewriter.writerow(['Regressive','mBed','UPP',f_dic['dpa_align','UPP','CLUSTALO']])\n",
    "\n",
    "    filewriter.writerow(['Regressive','mBed','Sparsecore',f_dic['dpa_align','MAFFT-SPARSECORE','CLUSTALO']])\n",
    "    filewriter.writerow(['Regressive','PartTree','Sparsecore',f_dic['dpa_align','MAFFT-SPARSECORE','MAFFT_PARTTREE']])\n",
    "    \n",
    "    filewriter.writerow(['Regressive','PartTree','Gins1',f_dic['dpa_align','MAFFT-GINSI','MAFFT_PARTTREE']])\n",
    "    filewriter.writerow(['Regressive','mBed','Gins1',f_dic['dpa_align','MAFFT-GINSI','CLUSTALO']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "# Export table for Figure 3A #\n",
    "##############################\n",
    "with open('results/tables/figure3b.csv', 'w') as csvfile:\n",
    "    filewriter = csv.writer(csvfile, delimiter=',')\n",
    "    \n",
    "    f_dic = full_top20_tc_avg_dict\n",
    "    cpu_dic = cpu_top20_dict\n",
    "\n",
    "    filewriter.writerow(['method','aggregation','score','cpu'])\n",
    "\n",
    "    filewriter.writerow(['Fftns1-PartTree','non-regressive',f_dic['std_align','MAFFT-FFTNS1','MAFFT_PARTTREE'],cpu_dic['std_align','MAFFT-FFTNS1','MAFFT_PARTTREE']])\n",
    "    filewriter.writerow(['Fftns1-PartTree','regressive',f_dic['dpa_align','MAFFT-FFTNS1','MAFFT_PARTTREE'],cpu_dic['dpa_align','MAFFT-FFTNS1','MAFFT_PARTTREE']]) \n",
    "\n",
    "    filewriter.writerow(['Fftns1-mBed','non-regressive',f_dic['std_align','MAFFT-FFTNS1','CLUSTALO'],cpu_dic['std_align','MAFFT-FFTNS1','CLUSTALO']])\n",
    "    filewriter.writerow(['Fftns1-mBed','regressive',f_dic['dpa_align','MAFFT-FFTNS1','CLUSTALO'],cpu_dic['dpa_align','MAFFT-FFTNS1','CLUSTALO']])\n",
    "    \n",
    "    filewriter.writerow(['ClustalO-PartTree','non-regressive',f_dic['std_align','CLUSTALO','MAFFT_PARTTREE'],cpu_dic['std_align','CLUSTALO','MAFFT_PARTTREE']])\n",
    "    filewriter.writerow(['ClustalO-PartTree','regressive',f_dic['dpa_align','CLUSTALO','MAFFT_PARTTREE'],cpu_dic['dpa_align','CLUSTALO','MAFFT_PARTTREE']])\n",
    "\n",
    "    filewriter.writerow(['ClustalO-mBed','non-regressive',f_dic['std_align','CLUSTALO','CLUSTALO'],cpu_dic['std_align','CLUSTALO','CLUSTALO']])\n",
    "    filewriter.writerow(['ClustalO-mBed','regressive',f_dic['dpa_align','CLUSTALO','CLUSTALO'],cpu_dic['dpa_align','CLUSTALO','CLUSTALO']])\n",
    "\n",
    "    filewriter.writerow(['UPP-mBed','non-regressive',f_dic['default_align', 'UPP', 'DEFAULT'],cpu_dic['default_align', 'UPP', 'DEFAULT']])\n",
    "    filewriter.writerow(['UPP-mBed','regressive',f_dic['dpa_align','UPP', 'CLUSTALO'],cpu_dic['dpa_align', 'UPP', 'CLUSTALO']])\n",
    "\n",
    "    filewriter.writerow(['Sparsecore-mBed','non-regressive',f_dic['default_align', 'MAFFT-SPARSECORE', 'DEFAULT'],cpu_dic['default_align', 'MAFFT-SPARSECORE', 'DEFAULT']])\n",
    "    filewriter.writerow(['Sparsecore-mBed','regressive',f_dic['dpa_align','MAFFT-SPARSECORE', 'CLUSTALO'],cpu_dic['dpa_align', 'MAFFT-SPARSECORE', 'CLUSTALO']])\n",
    " \n",
    "    filewriter.writerow(['Ginsi-mBed','regressive',f_dic['dpa_align', 'MAFFT-GINSI', 'CLUSTALO'],cpu_dic['dpa_align', 'MAFFT-GINSI', 'CLUSTALO']])\n",
    "    filewriter.writerow(['Ginsi-PartTree','regressive',f_dic['dpa_align', 'MAFFT-GINSI', 'MAFFT_PARTTREE'],cpu_dic['dpa_align', 'MAFFT-GINSI', 'MAFFT_PARTTREE']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
