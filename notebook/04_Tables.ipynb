{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tables\n",
    "\n",
    "The tables generated below are used both as guide trees in the progressive\n",
    "alignment proceedure as well as trees used in the clustering step \n",
    "of the regressive alignment proceedure.\n",
    "\n",
    "\n",
    "The generated tables can be found in the `results/tables/` directory of this repository.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "# Import python packages #\n",
    "##########################\n",
    "\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/edgar/CBCRG/dpa_v2/testAn'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################################################\n",
    "# Change directory relative to repository home #\n",
    "################################################\n",
    "\n",
    "pwd = os.getcwd()\n",
    "work_dir=pwd+\"/testAn\"\n",
    "os.chdir(work_dir)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ltn': '1068', 'il8': '1073', 'az': '1086', 'kringle': '1091', 'cryst': '1160', 'DEATH': '1183', 'cah': '1379', 'mmp': '1427', 'rub': '1435', 'ghf10': '1502', 'tgfb': '1606', 'sodcu': '2038', 'KAS': '2070', 'DMRL_synthase': '2099', 'tms': '2118', 'GEL': '2195', 'kunitz': '2266', 'Sulfotransfer': '2489', 'mofe': '2567', 'Ald_Xan_dh_2': '2589', 'ghf5': '2717', 'phc': '2957', 'aadh': '3127', 'annexin': '3139', 'serpin': '3144', 'cytb': '3206', 'asp': '3262', 'oxidored_q6': '3348', 'hpr': '3349', 'hormone_rec': '3509', 'hr': '3707', 'tim': '3904', 'glob': '3983', 'ace': '3989', 'cys': '4316', 'ghf1': '4358', 'sodfe': '4455', 'peroxidase': '4514', 'uce': '4558', 'flav': '4612', 'HMG_box': '4779', 'OTCace': '4795', 'msb': '4884', 'icd': '5678', 'proteasome': '5732', 'cyclo': '6288', 'LIM': '6428', 'HLH': '6781', 'ldh': '7367', 'subt': '7517', 'int': '7572', 'lyase_1': '7632', 'gpdh': '7691', 'egf': '7774', 'blm': '9105', 'gluts': '10099', 'myb_DNA-binding': '10398', 'tRNA-synt_2b': '11293', 'biotin_lipoyl': '11833', 'hom': '12037', 'ghf13': '12607', 'aldosered': '13277', 'hla': '13465', 'Rhodanese': '14049', 'PDZ': '14950', 'blmb': '17200', 'rhv': '17976', 'p450': '21013', 'adh': '21331', 'aat': '25100', 'rrm': '27610', 'Acetyltransf': '46285', 'sdr': '50157', 'zf-CCHH': '88345', 'rvp': '93681'}\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "# Read in the number of sequences for each dataset #\n",
    "####################################################\n",
    "\n",
    "with open(\"results/num_seqs.csv\", mode='r') as infile:\n",
    "    reader = csv.reader(infile, delimiter='\\t')\n",
    "    sizes_dict = {rows[0]:rows[1] for rows in reader}\n",
    "    \n",
    "print(sizes_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "# Function to read in accuracy and scores files #\n",
    "#################################################\n",
    "\n",
    "def scores_to_dict(scores_dir, scores_dict, tag):\n",
    "    scores_list=[]\n",
    "    for score_file in os.listdir(scores_dir):\n",
    "        family, align_type, bucket, aligner, tree, score_type = score_file.split('.')\n",
    "        y = tuple([tag, align_type, aligner, tree, family, score_type])\n",
    "        with open(scores_dir + score_file, 'r') as infile:\n",
    "            data = infile.read()\n",
    "        scores_dict[y]=data.rstrip()\n",
    "    return scores_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-b9666a2214bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mscores_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mavgID_scores_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"results/avgID/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mscores_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores_to_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavgID_scores_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"avgID\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mavgSum_scores_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"results_reference/avgSum/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-a320c773d94a>\u001b[0m in \u001b[0;36mscores_to_dict\u001b[0;34m(scores_dir, scores_dict, tag)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mscores_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mscore_file\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mfamily\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbucket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maligner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maligner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mscore_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 6)"
     ]
    }
   ],
   "source": [
    "##################################################\n",
    "# Read in the full and reference datasets scores #\n",
    "##################################################\n",
    "\n",
    "scores_dict = {}\n",
    "avgID_scores_dir=\"results/avgID/\"\n",
    "scores_dict = scores_to_dict(avgID_scores_dir, scores_dict, \"avgID\")\n",
    "\n",
    "avgSum_scores_dir=\"results_reference/avgSum/\"\n",
    "scores_dict = scores_to_dict(avgSum_scores_dir, scores_dict, \"avgSum\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################\n",
    "# Create a dictionary for average TC scores and CPU time when above 10,000 seqs #\n",
    "#################################################################################\n",
    "\n",
    "# Dictionary of the average TC scores and CPU time\n",
    "full_top20_tc_avg_dict={}\n",
    "ref_top20_tc_avg_dict={}\n",
    "cpu_top20_dict={}\n",
    "\n",
    "# Take all datasets and create a dictionary of average scores\n",
    "datasets=set([k[1]+'/'+k[2]+'/'+k[3] for k,v in scores_dict.items() ])\n",
    "\n",
    "# Calculate average TC score for each of the full datasets with over 10,000 sequences\n",
    "for dataset in datasets:\n",
    "    key = dataset.split(\"/\")\n",
    "    i = [v for k,v in scores_dict.items() if k[0]=='full' and k[1]==key[0] and k[2]==key[1] and k[3]==key[2] and int(sizes_dict[k[4]]) > 10000 and k[5]=='tc']\n",
    "    l = [float(j) for j in i]\n",
    "    if (len(l)==20):\n",
    "        avg = sum(l)/float(len(l))\n",
    "        full_top20_tc_avg_dict[tuple(key)]=avg\n",
    "\n",
    "# Calculate average TC for each of the reference datasets\n",
    "for dataset in datasets:\n",
    "    key = dataset.split(\"/\")\n",
    "    i = [v for k,v in scores_dict.items() if k[0]=='ref' and k[1]==key[0] and k[2]==key[1] and k[3]==key[2] and int(sizes_dict[k[4]]) > 10000 and k[5]=='tc']\n",
    "    l = [float(j) for j in i]\n",
    "    if (len(l)==20):\n",
    "        avg = sum(l)/float(len(l))\n",
    "        ref_top20_tc_avg_dict[tuple(key)]=avg\n",
    "\n",
    "# Calculate average CPU time required for each the datasets with over 10,000 sequences\n",
    "for dataset in datasets:\n",
    "    key = dataset.split(\"/\")\n",
    "    i = [v for k,v in scores_dict.items() if k[0]=='full' and k[1]==key[0] and k[2]==key[1] and k[3]==key[2] and int(sizes_dict[k[4]]) > 10000 and k[5]=='cpu']\n",
    "    l = [float(j) for j in i]\n",
    "    if (len(l)==20):\n",
    "        avg = sum(l)/float(len(l))\n",
    "        cpu_top20_dict[tuple(key)]=avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "# Export Table 1 as CSV #\n",
    "#########################\n",
    "\n",
    "with open('results/tables/table1.csv', 'w') as csvfile:\n",
    "    filewriter = csv.writer(csvfile, delimiter=',')\n",
    "\n",
    "    filewriter.writerow(['','','non-regressive','regressive','reference','non-regressive','regressive'])\n",
    "    filewriter.writerow(['tree method','MSA algorithm','score %','score %','score %','cpu time (ms)','cpu time (ms)'])\n",
    "\n",
    "    f_dic, r_dic, cpu_dic, aligner, tree = full_top20_tc_avg_dict, ref_top20_tc_avg_dict, cpu_top20_dict, 'MAFFT-FFTNS1', 'MAFFT_PARTTREE'\n",
    "    filewriter.writerow(['PartTree','Fftns1',round(f_dic['std_align',aligner,tree],2),round(f_dic['dpa_align',aligner,tree],2),round(r_dic['std_align',aligner,tree],2),cpu_dic['std_align',aligner,tree],cpu_dic['dpa_align',aligner,tree]])\n",
    " \n",
    "    f_dic, r_dic, cpu_dic, aligner, tree = full_top20_tc_avg_dict, ref_top20_tc_avg_dict, cpu_top20_dict, 'MAFFT-FFTNS1', 'CLUSTALO'\n",
    "    filewriter.writerow(['mBed','Fftns1',round(f_dic['std_align',aligner,tree],2),round(f_dic['dpa_align',aligner,tree],2),round(r_dic['std_align',aligner,tree],2),cpu_dic['std_align',aligner,tree],cpu_dic['dpa_align',aligner,tree]])\n",
    " \n",
    "    f_dic, r_dic, cpu_dic, aligner, tree = full_top20_tc_avg_dict, ref_top20_tc_avg_dict, cpu_top20_dict, 'CLUSTALO', 'MAFFT_PARTTREE'\n",
    "    filewriter.writerow(['PartTree','ClustalO',round(f_dic['std_align',aligner,tree],2),round(f_dic['dpa_align',aligner,tree],2),round(r_dic['std_align',aligner,tree],2),cpu_dic['std_align',aligner,tree],cpu_dic['dpa_align',aligner,tree]])\n",
    "\n",
    "    f_dic, r_dic, cpu_dic, aligner, tree = full_top20_tc_avg_dict, ref_top20_tc_avg_dict, cpu_top20_dict, 'CLUSTALO', 'CLUSTALO'\n",
    "    filewriter.writerow(['mBed','ClustalO',round(f_dic['std_align',aligner,tree],2),round(f_dic['dpa_align',aligner,tree],2),round(r_dic['std_align',aligner,tree],2),cpu_dic['std_align',aligner,tree],cpu_dic['dpa_align',aligner,tree]])\n",
    "    \n",
    "    filewriter.writerow(['Average','','','','','',''])\n",
    "    filewriter.writerow(['','','','','','',''])\n",
    "    \n",
    "    f_dic, r_dic, cpu_dic, aligner, tree = full_top20_tc_avg_dict, ref_top20_tc_avg_dict, cpu_top20_dict, 'UPP', 'DEFAULT'\n",
    "    filewriter.writerow(['default/mBed','UPP',round(f_dic['default_align',aligner,tree],2),round(f_dic['dpa_align',aligner,'CLUSTALO'],2),round(r_dic['default_align',aligner,tree],2),cpu_dic['default_align',aligner,'DEFAULT'],cpu_dic['dpa_align',aligner,'CLUSTALO']])\n",
    " \n",
    "    f_dic, r_dic, cpu_dic, aligner, tree = full_top20_tc_avg_dict, ref_top20_tc_avg_dict, cpu_top20_dict, 'MAFFT-SPARSECORE', 'DEFAULT'\n",
    "    filewriter.writerow(['default/mBed','Sparsecore',round(f_dic['default_align',aligner,tree],2),round(f_dic['dpa_align',aligner,'CLUSTALO'],2),round(r_dic['default_align',aligner,tree],2),cpu_dic['default_align',aligner,'DEFAULT'],cpu_dic['dpa_align',aligner,'CLUSTALO']])\n",
    " \n",
    "    f_dic, r_dic, cpu_dic, aligner, tree = full_top20_tc_avg_dict, ref_top20_tc_avg_dict, cpu_top20_dict, 'MAFFT-GINSI', 'MAFFT_PARTTREE'\n",
    "    filewriter.writerow(['PartTree','Gins1','-',round(f_dic['dpa_align',aligner,tree],2),round(r_dic['std_align',aligner,tree],2),'-',cpu_dic['dpa_align',aligner,tree]])\n",
    "\n",
    "    f_dic, r_dic, cpu_dic, aligner, tree = full_top20_tc_avg_dict, ref_top20_tc_avg_dict, cpu_top20_dict, 'MAFFT-GINSI', 'CLUSTALO'\n",
    "    filewriter.writerow(['mBed','Gins1','-',round(f_dic['dpa_align',aligner,tree],2),round(r_dic['std_align',aligner,tree],2),'-',cpu_dic['dpa_align',aligner,tree]]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################\n",
    "# Export all raw results as CSV table #\n",
    "#######################################\n",
    "\n",
    "with open('results/tables/full_table_sp.csv', 'w') as csvfile:\n",
    "    filewriter = csv.writer(csvfile, delimiter=',')\n",
    "    for e in scores_dict:\n",
    "        if e[5] == 'sp':\n",
    "            filewriter.writerow([e[0], e[1], e[2], e[3], e[4], sizes_dict[e[4]], scores_dict[e]])\n",
    "            \n",
    "with open('results/tables/full_table_tc.csv', 'w') as csvfile:\n",
    "    filewriter = csv.writer(csvfile, delimiter=',')\n",
    "    for e in scores_dict:\n",
    "        if e[5] == 'tc':\n",
    "            filewriter.writerow([e[0], e[1], e[2], e[3], e[4], sizes_dict[e[4]], scores_dict[e]])\n",
    "\n",
    "with open('results/tables/full_table_cpu.csv', 'w') as csvfile:\n",
    "    filewriter = csv.writer(csvfile, delimiter=',')\n",
    "    for e in scores_dict:\n",
    "        if e[5] == 'cpu':\n",
    "            filewriter.writerow([e[0], e[1], e[2], e[3], e[4], sizes_dict[e[4]], scores_dict[e]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "# Export table for CCA Figure 2B #\n",
    "##################################\n",
    "\n",
    "with open('results/tables/figure2b.csv', 'w') as csvfile:\n",
    "    filewriter = csv.writer(csvfile, delimiter=',')\n",
    "    \n",
    "    f_dic = full_top20_tc_avg_dict\n",
    "    \n",
    "    filewriter.writerow(['reg_method','tree_method','align_method','accuracy'])\n",
    "    \n",
    "    filewriter.writerow(['Non-Regressive','PartTree','Fftns1',f_dic['std_align','MAFFT-FFTNS1','MAFFT_PARTTREE']])\n",
    "    filewriter.writerow(['Non-Regressive','mBed','Fftns1',f_dic['std_align','MAFFT-FFTNS1','CLUSTALO']])\n",
    "    filewriter.writerow(['Non-Regressive','PartTree','ClustalO',f_dic['std_align','CLUSTALO','MAFFT_PARTTREE']])\n",
    "    filewriter.writerow(['Non-Regressive','mBed','ClustalO',f_dic['std_align','CLUSTALO','CLUSTALO']])\n",
    "    \n",
    "    filewriter.writerow(['Non-Regressive','UPP Tree','UPP',f_dic['default_align','UPP','DEFAULT']])\n",
    "    filewriter.writerow(['Non-Regressive','Sparsecore Tree','Sparsecore',f_dic['default_align','MAFFT-SPARSECORE','DEFAULT']])\n",
    "    \n",
    "    filewriter.writerow(['Regressive','PartTree','Fftns1',f_dic['dpa_align','MAFFT-FFTNS1','MAFFT_PARTTREE']])\n",
    "    filewriter.writerow(['Regressive','mBed','Fftns1',f_dic['dpa_align','MAFFT-FFTNS1','CLUSTALO']])\n",
    "    filewriter.writerow(['Regressive','PartTree','ClustalO',f_dic['dpa_align','CLUSTALO','MAFFT_PARTTREE']])\n",
    "    filewriter.writerow(['Regressive','mBed','ClustalO',f_dic['dpa_align','CLUSTALO','CLUSTALO']])\n",
    "    \n",
    "    filewriter.writerow(['Regressive','mBed','UPP',f_dic['dpa_align','UPP','CLUSTALO']])\n",
    "\n",
    "    filewriter.writerow(['Regressive','mBed','Sparsecore',f_dic['dpa_align','MAFFT-SPARSECORE','CLUSTALO']])\n",
    "    filewriter.writerow(['Regressive','PartTree','Sparsecore',f_dic['dpa_align','MAFFT-SPARSECORE','MAFFT_PARTTREE']])\n",
    "    \n",
    "    filewriter.writerow(['Regressive','PartTree','Gins1',f_dic['dpa_align','MAFFT-GINSI','MAFFT_PARTTREE']])\n",
    "    filewriter.writerow(['Regressive','mBed','Gins1',f_dic['dpa_align','MAFFT-GINSI','CLUSTALO']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "# Export table for Figure 3A #\n",
    "##############################\n",
    "with open('results/tables/figure3b.csv', 'w') as csvfile:\n",
    "    filewriter = csv.writer(csvfile, delimiter=',')\n",
    "    \n",
    "    f_dic = full_top20_tc_avg_dict\n",
    "    cpu_dic = cpu_top20_dict\n",
    "\n",
    "    filewriter.writerow(['method','aggregation','score','cpu'])\n",
    "\n",
    "    filewriter.writerow(['Fftns1-PartTree','non-regressive',f_dic['std_align','MAFFT-FFTNS1','MAFFT_PARTTREE'],cpu_dic['std_align','MAFFT-FFTNS1','MAFFT_PARTTREE']])\n",
    "    filewriter.writerow(['Fftns1-PartTree','regressive',f_dic['dpa_align','MAFFT-FFTNS1','MAFFT_PARTTREE'],cpu_dic['dpa_align','MAFFT-FFTNS1','MAFFT_PARTTREE']]) \n",
    "\n",
    "    filewriter.writerow(['Fftns1-mBed','non-regressive',f_dic['std_align','MAFFT-FFTNS1','CLUSTALO'],cpu_dic['std_align','MAFFT-FFTNS1','CLUSTALO']])\n",
    "    filewriter.writerow(['Fftns1-mBed','regressive',f_dic['dpa_align','MAFFT-FFTNS1','CLUSTALO'],cpu_dic['dpa_align','MAFFT-FFTNS1','CLUSTALO']])\n",
    "    \n",
    "    filewriter.writerow(['ClustalO-PartTree','non-regressive',f_dic['std_align','CLUSTALO','MAFFT_PARTTREE'],cpu_dic['std_align','CLUSTALO','MAFFT_PARTTREE']])\n",
    "    filewriter.writerow(['ClustalO-PartTree','regressive',f_dic['dpa_align','CLUSTALO','MAFFT_PARTTREE'],cpu_dic['dpa_align','CLUSTALO','MAFFT_PARTTREE']])\n",
    "\n",
    "    filewriter.writerow(['ClustalO-mBed','non-regressive',f_dic['std_align','CLUSTALO','CLUSTALO'],cpu_dic['std_align','CLUSTALO','CLUSTALO']])\n",
    "    filewriter.writerow(['ClustalO-mBed','regressive',f_dic['dpa_align','CLUSTALO','CLUSTALO'],cpu_dic['dpa_align','CLUSTALO','CLUSTALO']])\n",
    "\n",
    "    filewriter.writerow(['UPP-mBed','non-regressive',f_dic['default_align', 'UPP', 'DEFAULT'],cpu_dic['default_align', 'UPP', 'DEFAULT']])\n",
    "    filewriter.writerow(['UPP-mBed','regressive',f_dic['dpa_align','UPP', 'CLUSTALO'],cpu_dic['dpa_align', 'UPP', 'CLUSTALO']])\n",
    "\n",
    "    filewriter.writerow(['Sparsecore-mBed','non-regressive',f_dic['default_align', 'MAFFT-SPARSECORE', 'DEFAULT'],cpu_dic['default_align', 'MAFFT-SPARSECORE', 'DEFAULT']])\n",
    "    filewriter.writerow(['Sparsecore-mBed','regressive',f_dic['dpa_align','MAFFT-SPARSECORE', 'CLUSTALO'],cpu_dic['dpa_align', 'MAFFT-SPARSECORE', 'CLUSTALO']])\n",
    " \n",
    "    filewriter.writerow(['Ginsi-mBed','regressive',f_dic['dpa_align', 'MAFFT-GINSI', 'CLUSTALO'],cpu_dic['dpa_align', 'MAFFT-GINSI', 'CLUSTALO']])\n",
    "    filewriter.writerow(['Ginsi-PartTree','regressive',f_dic['dpa_align', 'MAFFT-GINSI', 'MAFFT_PARTTREE'],cpu_dic['dpa_align', 'MAFFT-GINSI', 'MAFFT_PARTTREE']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
